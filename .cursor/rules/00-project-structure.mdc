---
description: FAA 项目结构、入口与端到端数据流
alwaysApply: false
---
## 项目总览
- 核心理念：工程尽量固定，能力随模型/数据/Prompt 自动进化（详见 [ARCHITECTURE.md](mdc:ARCHITECTURE.md)、[readme.MD](mdc:readme.MD)）。
- 端到端链路：用户 → 渠道(Threema/API) → FastAPI → AI Engine → MCP Tools → PostgreSQL；Prompt Manager 提供可进化的行为约束与工具规格注入。

## 关键入口与目录
- API 入口：[src/api/main.py](mdc:src/api/main.py)
  - 应用生命周期管理（数据库、AI 引擎初始化、提醒后台任务）。
  - `/message` 测试与直连端点；`/health` 健康检查；`/media/get` 签名回退。
- Threema Webhook：[src/api/threema_webhook.py](mdc:src/api/threema_webhook.py)
  - 解密入站消息、保存附件（可派生 OCR/转写/视觉摘要）、识别或创建用户、调用 AI 引擎并回发。
  - Threema Gateway 服务封装：[src/services/threema_service.py](mdc:src/services/threema_service.py)
- AI 引擎（核心）：[src/ai_engine.py](mdc:src/ai_engine.py)
  - 轻理解→跟进合并→（可选）重理解→工具计划→执行→回复生成→持久化互动轨迹与对话回合。
  - 动态 MCP 工具发现与时间预算、向量缓存（trace 级与全局）。
- Prompt 管理与配置：
  - 管理器：[src/core/prompt_manager.py](mdc:src/core/prompt_manager.py)
  - 配置文件：[prompts/family_assistant_prompts.yaml](mdc:prompts/family_assistant_prompts.yaml)
  - LLM 客户端与配置：[src/core/llm_client.py](mdc:src/core/llm_client.py)、[src/core/config.py](mdc:src/core/config.py)
- MCP 服务与通用工具集：[mcp-server/generic_mcp_server.py](mdc:mcp-server/generic_mcp_server.py)
  - 无业务逻辑，提供 `store/search/aggregate/schedule_reminder/...` 等数据库能力。
- 数据层：
  - ORM 模型：[src/db/models.py](mdc:src/db/models.py)
  - Alembic 迁移：[alembic/versions/20250813_rename_reminders_sent_add_fk.py](mdc:alembic/versions/20250813_rename_reminders_sent_add_fk.py)

## 开发与运行
- 本地开发与部署参见：[DEPLOY.md](mdc:DEPLOY.md)、[docker-compose.yml](mdc:docker-compose.yml)、[docker/Dockerfile.dev](mdc:docker/Dockerfile.dev)。
- Prompt 与工具可独立演进：修改 YAML 或升级 MCP 工具无需改引擎代码。

## 设计关键点（务必遵循）
- AI 决策优先：避免在 API/服务层硬编码业务逻辑，一切通过 Prompt + 工具决定。
- 数据开放性：`memories.ai_understanding` 使用 JSONB，允许 AI 自主扩展字段；对金额/时间等关键字段提供精确列。
- 幂等与去重：优先使用 `external_id/source/version`，必要时走 `search + update_memory_fields`。
- 安全与隐私：在共享线程/群聊避免直显敏感信息；媒体访问使用签名回退或对象存储。