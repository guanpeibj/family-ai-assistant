# LLM Provider å¿«é€Ÿå‚è€ƒå¡

## ğŸ¯ 3 ç§’å¿«é€Ÿå¼€å§‹

```bash
# åœ¨ .env ä¸­è®¾ç½®
LLM_PROVIDER_NAME=qwen          # é€‰æ‹© provider
OPENAI_API_KEY=sk-xxx           # è®¾ç½® API Key

# é‡å¯åº”ç”¨ âœ… å®Œæˆï¼
```

## ğŸ“Š Provider å¯¹æ¯”é€ŸæŸ¥è¡¨

| Provider | æˆæœ¬ | é€Ÿåº¦ | æ¨èåœºæ™¯ | RPM |
|----------|------|------|---------|-----|
| **Qwen** â­ | Â¥ | âš¡ | **ç”Ÿäº§ç¯å¢ƒ** | 2000 |
| **DeepSeek** | Â¥ | âš¡ | æˆæœ¬æ§åˆ¶ | 500 |
| **Doubao** | Â¥ | âš¡ | å­—èŠ‚æŠ€æœ¯æ ˆ | 1000 |
| **Kimi** | Â¥Â¥Â¥Â¥ | âš¡âš¡ | é•¿æ–‡æœ¬ | 60 |
| **OpenAI** | $$$ | âš¡âš¡âš¡ | å›½é™…ç‰ˆ | 500 |
| **Claude** | $$$ | âš¡âš¡ | ç‰¹æ®Šæ¨ç† | 100 |

## ğŸ”§ å®Œæ•´é…ç½®ç¤ºä¾‹

### Qwenï¼ˆæ¨èï¼‰
```bash
LLM_PROVIDER_NAME=qwen
OPENAI_API_KEY=sk-xxx
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
OPENAI_MODEL=qwen-turbo
```

### DeepSeekï¼ˆæœ€ä¾¿å®œï¼‰
```bash
LLM_PROVIDER_NAME=deepseek
OPENAI_API_KEY=sk-xxx
OPENAI_BASE_URL=https://api.deepseek.com/v1
OPENAI_MODEL=deepseek-chat
```

### Doubaoï¼ˆå­—èŠ‚ç³»ï¼‰
```bash
LLM_PROVIDER_NAME=doubao
OPENAI_API_KEY=sk-xxx
OPENAI_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
OPENAI_MODEL=ep-20250101000000-xxxxx
```

### Kimiï¼ˆé•¿æ–‡æœ¬ï¼‰
```bash
LLM_PROVIDER_NAME=kimi
OPENAI_API_KEY=sk-xxx
OPENAI_BASE_URL=https://api.moonshot.cn/v1
OPENAI_MODEL=moonshot-v1-128k
```

## ğŸ’° æˆæœ¬è®¡ç®—

### æŸ¥è¯¢æˆæœ¬ï¼ˆä»£ç ï¼‰
```python
from src.core.llm_client import LLMClient

summary = LLMClient.get_usage_summary()
print(f"Total: ${summary['total_cost_usd']:.6f}")
print(f"Tokens: {summary['total_tokens']:,}")
```

### æˆæœ¬é¢„ä¼°è¡¨ï¼ˆ1M tokensï¼‰

| Provider | è¾“å…¥ | è¾“å‡º | æ€»è®¡ |
|----------|------|------|------|
| Qwen | Â¥300 | Â¥900 | Â¥1200 â‰ˆ $167 |
| DeepSeek | Â¥140 | Â¥280 | Â¥420 â‰ˆ $58 |
| Doubao | Â¥400 | Â¥1200 | Â¥1600 â‰ˆ $222 |
| Kimi | Â¥2000 | Â¥6000 | Â¥8000 â‰ˆ $1111 |
| OpenAI | $0.15 | $0.60 | $0.75 |

## âš™ï¸ é…ç½®é€ŸæŸ¥

### é™æµè®¾ç½®
```bash
LLM_RPM_LIMIT=0         # 0 = è‡ªåŠ¨ï¼Œ>0 = è¦†ç›–
LLM_CONCURRENCY=0       # 0 = è‡ªåŠ¨ï¼Œ>0 = è¦†ç›–
```

### ç¼“å­˜è®¾ç½®
```bash
LLM_ENABLE_CACHE=true
LLM_CACHE_TTL_SECONDS=30.0
LLM_CACHE_MAX_ITEMS=512
```

### Embedding é…ç½®
```bash
EMBED_PROVIDER=local_fastembed
FASTEMBED_MODEL=BAAI/bge-small-zh-v1.5
```

## ğŸ§ª æµ‹è¯•

```bash
# æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®
python3 examples/test_provider_config.py

# æŸ¥çœ‹æ‰€æœ‰ provider
python3 examples/test_provider_config.py | grep "å¯ç”¨çš„"

# æŸ¥çœ‹æˆæœ¬å¯¹æ¯”
python3 examples/test_provider_config.py | grep "æˆæœ¬å¯¹æ¯”" -A 10
```

## ğŸ”€ å¿«é€Ÿåˆ‡æ¢

ä» Kimi åˆ° DeepSeekï¼ˆèŠ‚çœ 95%ï¼‰ï¼š

```bash
# åŸé…ç½®
LLM_PROVIDER_NAME=kimi
OPENAI_API_KEY=sk-moonshot-xxx

# æ”¹ä¸º
LLM_PROVIDER_NAME=deepseek
OPENAI_API_KEY=sk-deepseek-xxx
OPENAI_BASE_URL=https://api.deepseek.com/v1

# é‡å¯ âœ…
```

## ğŸ› å¸¸è§é—®é¢˜é€Ÿè§£

| é—®é¢˜ | åŸå›  | è§£å†³ |
|------|------|------|
| "Unknown provider" | æ‹¼å†™é”™è¯¯ | æ£€æŸ¥ `LLM_PROVIDER_NAME` çš„å€¼ |
| é™æµäº† | è¶…è¿‡ RPM | é™ä½è¯·æ±‚é¢‘ç‡æˆ–å¢åŠ  `LLM_RPM_LIMIT` |
| Embedding æ…¢ | å›é€€åˆ° OpenAI | ç­‰å¾…æœ¬åœ°æ¨¡å‹åŠ è½½æˆ–æ£€æŸ¥ç½‘ç»œ |
| æˆæœ¬å¾ˆé«˜ | ç”¨äº†è´µçš„ provider | åˆ‡æ¢åˆ° DeepSeek æˆ– Qwen |

## ğŸ“– å®Œæ•´æ–‡æ¡£

- è¯¦ç»†é…ç½®ï¼š[LLM_PROVIDER_CONFIGURATION.md](docs/LLM_PROVIDER_CONFIGURATION.md)
- è¿ç§»æŒ‡å—ï¼š[MIGRATION_TO_NEW_LLM_SYSTEM.md](docs/MIGRATION_TO_NEW_LLM_SYSTEM.md)
- å®ç°æ€»ç»“ï¼š[IMPLEMENTATION_SUMMARY_LLM_PROVIDERS.md](IMPLEMENTATION_SUMMARY_LLM_PROVIDERS.md)

## ğŸš€ Pro æŠ€å·§

### æŠ€å·§ 1: å¤šç¯å¢ƒé…ç½®
```bash
# .env.dev
LLM_PROVIDER_NAME=deepseek

# .env.prod
LLM_PROVIDER_NAME=qwen

# åŠ è½½æŒ‡å®šç¯å¢ƒ
source .env.dev
```

### æŠ€å·§ 2: æˆæœ¬å‘Šè­¦
```python
from src.core.llm_client import LLMClient

summary = LLMClient.get_usage_summary()
if summary['total_cost_usd'] > 100:
    send_alert(f"High cost: ${summary['total_cost_usd']}")
```

### æŠ€å·§ 3: ä¸åŒä»»åŠ¡ç”¨ä¸åŒ provider
```python
# å¤æ‚æ¨ç†ç”¨ Kimi
kimi_client = LLMClient(provider_name="kimi")

# æ™®é€šä»»åŠ¡ç”¨ DeepSeek
cheap_client = LLMClient(provider_name="deepseek")
```

---

**ä¿å­˜æ­¤æ–‡ä»¶ä»¥ä¾›å¿«é€Ÿå‚è€ƒï¼** ğŸ“Œ
