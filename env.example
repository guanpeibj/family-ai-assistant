# FAA 环境变量配置
# 复制此文件为 .env 并填入实际值

# ========== 必需配置 ==========

# LLM Provider 选择
# 可选值：openai/kimi/qwen/doubao/deepseek/anthropic
# 默认使用 qwen（最稳定、性价比最高）
LLM_PROVIDER_NAME=qwen

# LLM API 密钥（必需）
OPENAI_API_KEY=sk-your-api-key-here

# LLM 模型名称和 API 地址
# 为空时自动使用 provider 预配置的默认值
# 可选择在此覆盖以使用特定模型
OPENAI_MODEL=
OPENAI_BASE_URL=

# AI Provider 类型（通常无需修改，自动由 LLM_PROVIDER_NAME 决定）
AI_PROVIDER=openai_compatible

# Embedding 模型
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ========== LLM 限流配置 ==========
# 为 0 时自动使用 provider 预配置
# 大于 0 时覆盖预配置

# 每分钟最大请求数（RPM）
# Qwen: 2000, Doubao: 1000, DeepSeek: 500, Kimi: 60
LLM_RPM_LIMIT=0

# 并发请求限制
# Qwen: 20, Doubao: 10, DeepSeek: 10, Kimi: 5
LLM_CONCURRENCY=0

# 其他 LLM 配置
LLM_MAX_RETRIES=1
LLM_BACKOFF_BASE_SECONDS=1.0
LLM_COOLDOWN_SECONDS=20.0
LLM_ENABLE_CACHE=true
LLM_CACHE_TTL_SECONDS=30.0
LLM_CACHE_MAX_ITEMS=512

# 低预算模式（跳过部分 LLM 环节以减少调用）
LOW_LLM_BUDGET=false

# ========== Embedding 提供方 ==========
# 本地 fastembed（推荐，无需 API）或 openai_compatible
EMBED_PROVIDER=local_fastembed
FASTEMBED_MODEL=BAAI/bge-small-zh-v1.5

# ========== 使用量追踪 ==========
# 启用 LLM 使用量追踪（记录 API 调用数和 token 消耗）
# 不计算成本，用户应根据官方定价自行计算
ENABLE_USAGE_TRACKING=true

# ========== 数据库 ==========
# PostgreSQL 密码（Docker Compose 需要）
POSTGRES_PASSWORD=faa_secret

# PostgreSQL 连接字符串（本地开发用）
# Docker 环境会自动构建，无需手动配置
DATABASE_URL=postgresql://faa:faa_secret@localhost:15432/family_assistant

# 应用密钥（请生成随机字符串）
SECRET_KEY=your_random_secret_key_here

# ========== Anthropic (可选) ==========
# AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-7-sonnet-latest

# ========== Threema Gateway (可选) ==========
THREEMA_GATEWAY_ID=*XXXXXXX
THREEMA_SECRET=your_threema_secret
THREEMA_PRIVATE_KEY=
THREEMA_WEBHOOK_URL=

# ========== 媒体与多模态 ==========
MEDIA_ROOT=/data/media
MEDIA_PUBLIC_BASE_URL=
SIGNING_SECRET=your_signing_secret_here

# 多模态能力开关
ENABLE_STT=true
OPENAI_STT_MODEL=whisper-1
ENABLE_OCR=false
ENABLE_VISION=false
OPENAI_VISION_MODEL=gpt-4o-mini

# ========== 高级配置 ==========
LOG_LEVEL=INFO
APP_ENV=production

# ========== 测试评估器 LLM 配置 ==========
EVALUATOR_LLM_PROVIDER=openai_compatible
EVALUATOR_LLM_MODEL=gpt-4o-mini
EVALUATOR_LLM_BASE_URL=https://api.openai.com/v1
# EVALUATOR_LLM_API_KEY=  # 留空则使用 OPENAI_API_KEY


# ========== Provider 配置示例 ==========

# --- Qwen (推荐，最稳定、最便宜) ---
# LLM_PROVIDER_NAME=qwen
# OPENAI_API_KEY=sk-xxx  # Qwen API Key
# OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# OPENAI_MODEL=qwen-turbo  # 或 qwen-plus, qwen-max
# 成本：¥0.0003/1K input, ¥0.0009/1K output
# RPM 限制：2000（非常宽松）
# 推荐用于：生产环境、日常测试


# --- DeepSeek (最便宜) ---
# LLM_PROVIDER_NAME=deepseek
# OPENAI_API_KEY=sk-xxx  # DeepSeek API Key
# OPENAI_BASE_URL=https://api.deepseek.com/v1
# OPENAI_MODEL=deepseek-chat
# 成本：¥0.00014/1K input, ¥0.00028/1K output（性价比之王）
# RPM 限制：500
# 推荐用于：成本控制、测试验证


# --- Doubao (字节系，性能稳定) ---
# LLM_PROVIDER_NAME=doubao
# OPENAI_API_KEY=sk-xxx  # Doubao API Key
# OPENAI_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
# OPENAI_MODEL=ep-20250101000000-xxxxx  # 替换为实际的 Endpoint ID
# 成本：¥0.0004/1K input, ¥0.0012/1K output
# RPM 限制：1000
# 推荐用于：生产环境、字节技术栈


# --- Kimi/Moonshot (长文本处理能力强) ---
# LLM_PROVIDER_NAME=kimi
# OPENAI_API_KEY=sk-xxx  # Kimi API Key
# OPENAI_BASE_URL=https://api.moonshot.cn/v1
# OPENAI_MODEL=moonshot-v1-128k
# 成本：¥0.002/1K input, ¥0.006/1K output
# RPM 限制：60（相对严格）
# 推荐用于：处理长文本、复杂推理


# --- OpenAI (国际版，最稳定但最贵) ---
# LLM_PROVIDER_NAME=openai
# OPENAI_API_KEY=sk-xxx  # OpenAI API Key
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini
# 成本：$0.00015/1K input, $0.0006/1K output
# RPM 限制：500
# 推荐用于：非中文使用、特殊场景