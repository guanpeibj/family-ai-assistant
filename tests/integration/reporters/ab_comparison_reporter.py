"""
ABæµ‹è¯•å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆå™¨
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any
from validators.scoring import TestSuiteSummary, ScoringSystem


class ABComparisonReporter:
    """ABæµ‹è¯•å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_report(
        comparison_id: str,
        description: str,
        variant_a_config: Dict[str, Any],
        variant_b_config: Dict[str, Any],
        summary_a: TestSuiteSummary,
        summary_b: TestSuiteSummary,
        output_dir: Path
    ) -> Path:
        """
        ç”ŸæˆABå¯¹æ¯”æŠ¥å‘Š
        
        Args:
            comparison_id: å¯¹æ¯”ID
            description: æè¿°
            variant_a_config: Aå˜ä½“é…ç½®
            variant_b_config: Bå˜ä½“é…ç½®
            summary_a: Aå˜ä½“æµ‹è¯•æ€»ç»“
            summary_b: Bå˜ä½“æµ‹è¯•æ€»ç»“
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨è¯„åˆ†ç³»ç»Ÿè®¡ç®—å¯¹æ¯”
        comparison = ScoringSystem.compare_summaries(
            summary_a, summary_b,
            name_a=variant_a_config.get("name", "A"),
            name_b=variant_b_config.get("name", "B")
        )
        
        # ç”Ÿæˆæ¨è
        recommendation = ABComparisonReporter._generate_recommendation(
            summary_a, summary_b, comparison
        )
        
        report = {
            "comparison_id": comparison_id,
            "timestamp": datetime.now().isoformat(),
            "description": description,
            "variant_a": {
                **comparison["variant_a"],
                "config": variant_a_config
            },
            "variant_b": {
                **comparison["variant_b"],
                "config": variant_b_config
            },
            "comparison": comparison["comparison"],
            "recommendation": recommendation
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        output_dir.mkdir(parents=True, exist_ok=True)
        report_file = output_dir / f"ab_{comparison_id}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        text_report = ABComparisonReporter._generate_text_report(report)
        text_file = output_dir / f"ab_{comparison_id}.txt"
        
        with open(text_file, 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        return report_file
    
    @staticmethod
    def _generate_recommendation(
        summary_a: TestSuiteSummary,
        summary_b: TestSuiteSummary,
        comparison: Dict
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨è"""
        score_diff = comparison["comparison"]["score_diff"]
        duration_diff = comparison["comparison"]["duration_diff"]
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆè´¨é‡æƒé‡0.7ï¼Œé€Ÿåº¦æƒé‡0.3ï¼‰
        # è´¨é‡å½’ä¸€åŒ–ï¼šåˆ†æ•°/100
        # é€Ÿåº¦å½’ä¸€åŒ–ï¼š-æ—¶é—´å·®/10ï¼ˆè´Ÿå€¼è¡¨ç¤ºæ›´å¿«æ›´å¥½ï¼‰
        quality_a = summary_a.avg_total_score / 100
        quality_b = summary_b.avg_total_score / 100
        
        speed_a = 1.0  # åŸºå‡†
        speed_b = 1.0 - (duration_diff / summary_a.avg_duration) if summary_a.avg_duration > 0 else 1.0
        
        value_a = quality_a * 0.7 + speed_a * 0.3
        value_b = quality_b * 0.7 + speed_b * 0.3
        
        # åˆ¤æ–­æ˜¾è‘—æ€§
        score_significant = abs(score_diff) >= 3  # 3åˆ†ä»¥ä¸Šè®¤ä¸ºæ˜¾è‘—
        speed_significant = abs(duration_diff) >= 2  # 2ç§’ä»¥ä¸Šè®¤ä¸ºæ˜¾è‘—
        
        # ç”Ÿæˆæ¨è
        if value_b > value_a + 0.05:  # 5%ä»¥ä¸Šçš„ä¼˜åŠ¿
            winner = "variant_b"
            reason = ABComparisonReporter._build_reason(
                summary_b, summary_a, score_diff, duration_diff,
                score_significant, speed_significant, True
            )
        elif value_a > value_b + 0.05:
            winner = "variant_a"
            reason = ABComparisonReporter._build_reason(
                summary_a, summary_b, -score_diff, -duration_diff,
                score_significant, speed_significant, False
            )
        else:
            winner = "tie"
            reason = "ä¸¤ä¸ªå˜ä½“è¡¨ç°ç›¸å½“ï¼Œå·®å¼‚ä¸æ˜¾è‘—"
        
        return {
            "overall": winner,
            "reason": reason,
            "confidence": min(abs(value_b - value_a) * 2, 0.95),
            "score_significant": score_significant,
            "speed_significant": speed_significant
        }
    
    @staticmethod
    def _build_reason(
        winner_summary: TestSuiteSummary,
        loser_summary: TestSuiteSummary,
        score_diff: float,
        duration_diff: float,
        score_significant: bool,
        speed_significant: bool,
        is_b: bool
    ) -> str:
        """æ„å»ºæ¨èç†ç”±"""
        reasons = []
        
        if score_significant:
            if score_diff > 0:
                reasons.append(f"è´¨é‡æ˜¾è‘—æ›´é«˜ï¼ˆ+{score_diff:.1f}åˆ†ï¼‰")
            else:
                reasons.append(f"è´¨é‡ç•¥ä½ï¼ˆ{score_diff:.1f}åˆ†ï¼‰")
        
        if speed_significant:
            if duration_diff < 0:
                reasons.append(f"é€Ÿåº¦æ˜¾è‘—æ›´å¿«ï¼ˆ{-duration_diff:.1f}ç§’ï¼‰")
            else:
                reasons.append(f"é€Ÿåº¦è¾ƒæ…¢ï¼ˆ+{duration_diff:.1f}ç§’ï¼‰")
        
        if not reasons:
            reasons.append("ç»¼åˆè¡¨ç°æ›´ä¼˜")
        
        return "ï¼Œ".join(reasons)
    
    @staticmethod
    def _generate_text_report(report: Dict) -> str:
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š"""
        lines = []
        lines.append("=" * 80)
        lines.append("FAA ABæµ‹è¯•å¯¹æ¯”æŠ¥å‘Š")
        lines.append("=" * 80)
        lines.append(f"å¯¹æ¯”ID: {report['comparison_id']}")
        lines.append(f"æè¿°: {report['description']}")
        lines.append(f"æ—¶é—´: {report['timestamp']}")
        lines.append("")
        
        # å˜ä½“A
        lines.append("ğŸ…°ï¸  å˜ä½“A:")
        lines.append(f"  é…ç½®: {report['variant_a']['config']}")
        lines.append(f"  å¹³å‡åˆ†: {report['variant_a']['avg_score']:.1f}/100")
        lines.append(f"  å¹³å‡è€—æ—¶: {report['variant_a']['avg_duration']:.1f}ç§’")
        lines.append(f"  é€šè¿‡ç‡: {report['variant_a']['pass_rate']*100:.1f}%")
        lines.append("")
        
        # å˜ä½“B
        lines.append("ğŸ…±ï¸  å˜ä½“B:")
        lines.append(f"  é…ç½®: {report['variant_b']['config']}")
        lines.append(f"  å¹³å‡åˆ†: {report['variant_b']['avg_score']:.1f}/100")
        lines.append(f"  å¹³å‡è€—æ—¶: {report['variant_b']['avg_duration']:.1f}ç§’")
        lines.append(f"  é€šè¿‡ç‡: {report['variant_b']['pass_rate']*100:.1f}%")
        lines.append("")
        
        # å¯¹æ¯”åˆ†æ
        comp = report['comparison']
        lines.append("ğŸ“Š å¯¹æ¯”åˆ†æ:")
        lines.append(f"  åˆ†æ•°å·®å¼‚: {comp['score_diff']:+.1f}åˆ†")
        lines.append(f"  è€—æ—¶å·®å¼‚: {comp['duration_diff']:+.1f}ç§’")
        lines.append(f"  é€šè¿‡ç‡å·®å¼‚: {comp['pass_rate_diff']:+.1%}")
        lines.append("")
        
        # åˆ†å±‚å¯¹æ¯”
        lines.append("åˆ†å±‚å¯¹æ¯”:")
        layer_comp = comp['layer_comparison']
        for layer_name, layer_data in layer_comp.items():
            lines.append(f"  {layer_name}:")
            lines.append(f"    A: {layer_data['a']:.1f}  B: {layer_data['b']:.1f}  å·®å¼‚: {layer_data['diff']:+.1f}")
        lines.append("")
        
        # æ¨è
        rec = report['recommendation']
        lines.append("ğŸ’¡ æ¨è:")
        winner_name = {"variant_a": "å˜ä½“A", "variant_b": "å˜ä½“B", "tie": "ä¸¤è€…ç›¸å½“"}
        lines.append(f"  é€‰æ‹©: {winner_name[rec['overall']]}")
        lines.append(f"  ç†ç”±: {rec['reason']}")
        lines.append(f"  ç½®ä¿¡åº¦: {rec['confidence']*100:.0f}%")
        lines.append("")
        
        lines.append("=" * 80)
        
        return "\n".join(lines)

