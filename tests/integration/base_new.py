"""
é›†æˆæµ‹è¯•åŸºç¡€ç±» V2 - AIé©±åŠ¨çš„è¯„ä¼°ç³»ç»Ÿ

æ ¸å¿ƒç†å¿µï¼š
1. ä¸æµ‹AIæ€ä¹ˆè¯´ï¼Œæµ‹AIåšäº†ä»€ä¹ˆ
2. ç”¨AIè¯„ä¼°AIï¼Œæ”¯æŒèƒ½åŠ›è¿›åŒ–
3. é‡åŒ–è¯„åˆ†ï¼Œæ”¯æŒABæµ‹è¯•å’Œæ¨¡å‹å¯¹æ¯”

ä¸‰å±‚éªŒè¯ï¼š
- æ•°æ®å±‚ (40åˆ†): AIæ˜¯å¦æ­£ç¡®æ‰§è¡Œäº†ä»»åŠ¡
- æ™ºèƒ½å±‚ (40åˆ†): AIæ˜¯å¦èªæ˜åœ°ç†è§£å’Œå¤„ç†
- ä½“éªŒå±‚ (20åˆ†): AIæ˜¯å¦æä¾›äº†è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒ
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
import structlog
import uuid

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.ai_engine import ai_engine
from src.db.database import get_session
from src.db.models import Memory, User, Reminder, Interaction
from sqlalchemy import select, delete

from validators import DataValidator, AIEvaluator, ScoringSystem
from validators.scoring import TestScore

logger = structlog.get_logger(__name__)


class IntegrationTestBase:
    """
    é›†æˆæµ‹è¯•åŸºç±» V2
    
    åŠŸèƒ½ï¼š
    1. ä¸‰å±‚éªŒè¯ç³»ç»Ÿï¼ˆæ•°æ®/æ™ºèƒ½/ä½“éªŒï¼‰
    2. é‡åŒ–è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    3. AIè¯„ä¼°å‘˜ï¼ˆç”¨AIè¯„ä¼°AIï¼‰
    4. è¯¦ç»†æŠ¥å‘Šç”Ÿæˆ
    5. æ”¯æŒABæµ‹è¯•å’Œæ¨¡å‹å¯¹æ¯”
    """
    
    # æµ‹è¯•ç”¨æˆ·UUIDå‘½åç©ºé—´ï¼ˆå›ºå®šUUIDï¼Œç”¨äºç”Ÿæˆç¡®å®šæ€§çš„æµ‹è¯•ç”¨æˆ·UUIDï¼‰
    TEST_USER_NAMESPACE = uuid.UUID('00000000-0000-0000-0000-000000000000')
    
    def __init__(self, test_suite_name: str = "base"):
        """
        åˆå§‹åŒ–æµ‹è¯•åŸºç±»
        
        Args:
            test_suite_name: æµ‹è¯•å¥—ä»¶åç§°
        """
        self.test_suite_name = test_suite_name
        # ä½¿ç”¨UUID v5ç”Ÿæˆç¡®å®šæ€§çš„æµ‹è¯•ç”¨æˆ·UUIDï¼ˆåŸºäºsuiteåç§°ï¼‰
        self.test_user_uuid = uuid.uuid5(self.TEST_USER_NAMESPACE, f"test_integration_{test_suite_name}")
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºJSONåºåˆ—åŒ–ï¼ˆä¼ é€’ç»™AIå¼•æ“å’ŒMCPå·¥å…·ï¼‰
        self.test_user_id = str(self.test_user_uuid)
        self.test_scores: List[TestScore] = []
        self.setup_complete = False
        
        # åˆå§‹åŒ–éªŒè¯å™¨ï¼ˆä¼ é€’å­—ç¬¦ä¸²IDï¼‰
        self.data_validator = DataValidator(self.test_user_id)
        self.ai_evaluator = AIEvaluator(use_cache=True)
        
    async def setup(self):
        """
        æµ‹è¯•å‰åˆå§‹åŒ–
        """
        logger.info("test_setup_start", suite=self.test_suite_name)
        
        try:
            # åˆå§‹åŒ–AIå¼•æ“
            if ai_engine.mcp_client is None:
                await ai_engine.initialize_mcp()
            
            # æ¸…ç†æ—§æ•°æ®
            await self._cleanup_test_data()
            
            logger.info("test_setup_complete", suite=self.test_suite_name)
            self.setup_complete = True
            return True
            
        except Exception as e:
            logger.error("test_setup_failed", suite=self.test_suite_name, error=str(e))
            return False
    
    async def teardown(self):
        """æµ‹è¯•åæ¸…ç†"""
        logger.info("test_teardown", suite=self.test_suite_name, 
                   test_count=len(self.test_scores))
    
    async def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        await self._cleanup_test_data()
        logger.info("test_data_cleaned", suite=self.test_suite_name)
    
    async def _cleanup_test_data(self):
        """å†…éƒ¨æ–¹æ³•ï¼šæ¸…ç†æµ‹è¯•æ•°æ®"""
        try:
            async with get_session() as session:
                # ä½¿ç”¨UUIDå¯¹è±¡è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢ï¼ˆSQLAlchemyæ”¯æŒUUIDç±»å‹ï¼‰
                # åˆ é™¤ç›¸å…³æ•°æ®
                await session.execute(
                    delete(Memory).where(Memory.user_id == self.test_user_uuid)
                )
                await session.execute(
                    delete(Reminder).where(Reminder.memory_id.in_(
                        select(Memory.id).where(Memory.user_id == self.test_user_uuid)
                    ))
                )
                await session.execute(
                    delete(Interaction).where(Interaction.user_id == self.test_user_uuid)
                )
                
                logger.info("test_data_cleanup_complete", 
                          user_id=self.test_user_id,  # å·²ç»æ˜¯å­—ç¬¦ä¸²
                          suite=self.test_suite_name)
                    
        except Exception as e:
            logger.error("test_data_cleanup_failed", error=str(e))
    
    async def run_test(
        self, 
        test_id: str,
        test_name: str, 
        message: str,
        expected_behavior: Dict[str, Any],
        data_verification: Optional[Dict[str, Any]] = None,
        intelligence_check: Optional[Dict[str, Any]] = None,
        experience_check: Optional[Dict[str, Any]] = None,
        context: Optional[Dict] = None,
    ) -> TestScore:
        """
        è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹ - å®Œæ•´çš„ä¸‰å±‚éªŒè¯
        
        Args:
            test_id: æµ‹è¯•ç”¨ä¾‹IDï¼ˆå¦‚TC001ï¼‰
            test_name: æµ‹è¯•åç§°
            message: ç”¨æˆ·è¾“å…¥æ¶ˆæ¯
            expected_behavior: é¢„æœŸè¡Œä¸ºæè¿°
            data_verification: æ•°æ®å±‚éªŒè¯è§„åˆ™
            intelligence_check: æ™ºèƒ½å±‚éªŒè¯è¦ç‚¹
            experience_check: ä½“éªŒå±‚éªŒè¯è¦ç‚¹
            context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            TestScoreå¯¹è±¡ï¼ŒåŒ…å«å®Œæ•´çš„è¯„åˆ†å’Œåˆ†æ
        """
        print()
        print("=" * 80)
        print(f"[{test_id}] {test_name}")
        print("=" * 80)
        print(f"ğŸ“ è¾“å…¥ï¼š{message}")
        print()
        
        start_time = datetime.now()
        
        try:
            # ===== æ­¥éª¤1ï¼šè°ƒç”¨AIå¼•æ“ =====
            test_context = {
                "channel": "api",
                "thread_id": f"test_thread_{self.test_suite_name}",
                **(context or {})
            }
            
            # ä¼ é€’å­—ç¬¦ä¸²æ ¼å¼çš„user_idç»™AIå¼•æ“ï¼ˆç”¨äºJSONåºåˆ—åŒ–ï¼‰
            response = await ai_engine.process_message(
                content=message,
                user_id=self.test_user_id,  # å·²ç»æ˜¯å­—ç¬¦ä¸²
                context=test_context
            )
            
            duration = (datetime.now() - start_time).total_seconds()
            
            print(f"ğŸ¤– AIå›å¤ï¼š")
            print(response)
            print()
            print(f"â±ï¸  è€—æ—¶ï¼š{duration:.2f}ç§’")
            print()
            
            # ===== æ­¥éª¤2ï¼šä¸‰å±‚éªŒè¯ =====
            
            # 2.1 æ•°æ®å±‚éªŒè¯ (40åˆ†)
            print("ğŸ“Š æ•°æ®å±‚éªŒè¯ä¸­...")
            data_result = {"score": 40, "details": {}, "issues": []}
            if data_verification:
                data_validation_result = await self.data_validator.verify(
                    expected=data_verification,
                    test_context=test_context
                )
                data_result = data_validation_result.to_dict()
                print(f"   åˆ†æ•°: {data_result['score']:.1f}/40")
            
            # âœ… æˆæœ¬ä¼˜åŒ–ï¼šæ•°æ®å±‚<90%æ—¶è·³è¿‡AIè¯„ä¼°ï¼ˆèŠ‚çœæˆæœ¬ï¼‰
            data_score_threshold = 36.0  # 90% * 40åˆ†
            skip_ai_evaluation = data_result['score'] < data_score_threshold
            
            if skip_ai_evaluation:
                print(f"âš ï¸  æ•°æ®å±‚å¾—åˆ†è¿‡ä½({data_result['score']:.1f}/40 < {data_score_threshold})")
                print("   è·³è¿‡æ™ºèƒ½å±‚å’Œä½“éªŒå±‚è¯„ä¼°ï¼ˆèŠ‚çœæˆæœ¬ï¼‰")
                
                # ç›´æ¥ç»™0åˆ†ï¼Œä¸è°ƒç”¨AIè¯„ä¼°å™¨
                intelligence_result = {
                    "score": 0,
                    "dimensions": {
                        "intent_understanding": 0,
                        "information_extraction": 0,
                        "context_usage": 0,
                        "response_relevance": 0
                    },
                    "reasoning": "æ•°æ®å±‚æœªè¾¾æ ‡(<90%)ï¼Œè·³è¿‡AIè¯„ä¼°",
                    "suggestions": ["ä¼˜å…ˆä¿®å¤æ•°æ®å±‚é—®é¢˜"]
                }
                
                experience_result = {
                    "score": 0,
                    "dimensions": {
                        "persona_alignment": 0,
                        "language_quality": 0,
                        "information_completeness": 0,
                        "user_friendliness": 0
                    },
                    "reasoning": "æ•°æ®å±‚æœªè¾¾æ ‡(<90%)ï¼Œè·³è¿‡AIè¯„ä¼°",
                    "suggestions": []
                }
                
            else:
                # 2.2 æ™ºèƒ½å±‚è¯„ä¼° (40åˆ†) - ç”¨AIè¯„ä¼°
                print("ğŸ§  æ™ºèƒ½å±‚è¯„ä¼°ä¸­...")
                test_case = {
                    "test_id": test_id,
                    "test_name": test_name,
                    "user_input": message,
                    "expected_behavior": expected_behavior
                }
                
                # è·å–æ•°æ®åº“æ•°æ®ç”¨äºè¯„ä¼°
                db_data = await self._get_latest_memory_data()
                
                intelligence_evaluation = await self.ai_evaluator.evaluate_intelligence(
                    test_case=test_case,
                    ai_response=response,
                    db_data=db_data
                )
                intelligence_result = intelligence_evaluation.to_dict()
                print(f"   åˆ†æ•°: {intelligence_result['score']:.1f}/40")
                
                # 2.3 ä½“éªŒå±‚è¯„ä¼° (20åˆ†) - ç”¨AIè¯„ä¼°
                print("âœ¨ ä½“éªŒå±‚è¯„ä¼°ä¸­...")
                experience_evaluation = await self.ai_evaluator.evaluate_experience(
                    test_case=test_case,
                    ai_response=response
                )
                experience_result = experience_evaluation.to_dict()
                print(f"   åˆ†æ•°: {experience_result['score']:.1f}/20")
            
            # ===== æ­¥éª¤3ï¼šè®¡ç®—æ€»åˆ† =====
            # æ„å»ºå¯¹è¯è®°å½•
            conversation = [
                f"user({self.test_user_id})- {message}",
                f"faa- {response}"
            ]
            
            test_score = ScoringSystem.calculate_test_score(
                test_id=test_id,
                test_name=test_name,
                data_result=data_result,
                intelligence_result=intelligence_result,
                experience_result=experience_result,
                duration=duration,
                conversation=conversation
            )
            
            # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            self.test_scores.append(test_score)
            
            # ===== æ‰“å°ç»“æœ =====
            print()
            print(f"{'='*80}")
            if test_score.success:
                print(f"âœ… æµ‹è¯•é€šè¿‡ - æ€»åˆ†: {test_score.total_score:.1f}/100 (ç­‰çº§{test_score.get_grade()})")
            else:
                print(f"âŒ æµ‹è¯•å¤±è´¥ - æ€»åˆ†: {test_score.total_score:.1f}/100 (ç­‰çº§{test_score.get_grade()})")
            
            print(f"   æ•°æ®å±‚: {test_score.data_score:.1f}/40")
            print(f"   æ™ºèƒ½å±‚: {test_score.intelligence_score:.1f}/40")
            print(f"   ä½“éªŒå±‚: {test_score.experience_score:.1f}/20")
            
            if test_score.issues:
                print()
                print("âš ï¸  æ”¹è¿›å»ºè®®:")
                for i, issue in enumerate(test_score.issues[:5], 1):  # æœ€å¤šæ˜¾ç¤º5æ¡
                    print(f"   {i}. {issue}")
            
            print(f"{'='*80}")
            
            return test_score
            
        except Exception as e:
            logger.error("test_execution_failed", test_id=test_id, error=str(e))
            print(f"âŒ æµ‹è¯•å¼‚å¸¸ï¼š{e}")
            
            # åˆ›å»ºå¤±è´¥çš„è¯„åˆ†
            duration = (datetime.now() - start_time).total_seconds()
            conversation = [f"user({self.test_user_id})- {message}"]
            
            test_score = TestScore(
                test_id=test_id,
                test_name=test_name,
                data_score=0,
                intelligence_score=0,
                experience_score=0,
                total_score=0,
                data_details={},
                intelligence_details={},
                experience_details={},
                duration=duration,
                success=False,
                issues=[f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"],
                conversation=conversation
            )
            
            self.test_scores.append(test_score)
            return test_score
    
    async def _get_latest_memory_data(self) -> Optional[Dict]:
        """è·å–æœ€æ–°çš„è®°å¿†æ•°æ®ç”¨äºè¯„ä¼°"""
        try:
            async with get_session() as session:
                # ä½¿ç”¨UUIDå¯¹è±¡è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢
                query = select(Memory).where(
                    Memory.user_id == self.test_user_uuid
                ).order_by(Memory.created_at.desc()).limit(1)
                
                result = await session.execute(query)
                memory = result.scalars().first()
                
                if memory:
                    return {
                        "id": str(memory.id),
                        "content": memory.content,
                        "ai_understanding": memory.ai_understanding,
                        "amount": float(memory.amount) if memory.amount else None,
                        "occurred_at": str(memory.occurred_at) if memory.occurred_at else None,
                        "created_at": str(memory.created_at)
                    }
                return None
                
        except Exception as e:
            logger.error("get_latest_memory_failed", error=str(e))
            return None
    
    async def run_multi_turn_test(
        self,
        test_id: str,
        test_name: str,
        turns: List[Dict[str, Any]],
        context: Optional[Dict] = None,
        fail_fast: bool = False
    ) -> TestScore:
        """
        è¿è¡Œå¤šè½®å¯¹è¯æµ‹è¯•
        
        Args:
            test_id: æµ‹è¯•ç”¨ä¾‹IDï¼ˆå¦‚MT001ï¼‰
            test_name: æµ‹è¯•åç§°
            turns: å¤šè½®å¯¹è¯åˆ—è¡¨ï¼Œæ¯è½®åŒ…å«user_inputã€expected_behaviorã€data_verification
            context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            fail_fast: å¦‚æœæŸè½®ä¸¥é‡å¤±è´¥(<50%)ï¼Œæ˜¯å¦æå‰ç»ˆæ­¢ï¼ˆé»˜è®¤Falseï¼Œç»§ç»­æµ‹è¯•ï¼‰
        
        Returns:
            TestScoreå¯¹è±¡ï¼Œæ±‡æ€»æ‰€æœ‰è½®æ¬¡çš„è¯„åˆ†
        """
        print()
        print("=" * 80)
        print(f"[{test_id}] {test_name} (å¤šè½®å¯¹è¯ï¼Œå…±{len(turns)}è½®)")
        print("=" * 80)
        
        start_time = datetime.now()
        turn_results = []
        
        # âœ… æ¯ä¸ªå¤šè½®æµ‹è¯•ä½¿ç”¨ç‹¬ç«‹çš„thread_idï¼Œé¿å…æ±¡æŸ“
        test_context = {
            "channel": "api",
            "thread_id": f"multi_turn_{test_id}_{datetime.now().strftime('%H%M%S')}",
            **(context or {})
        }
        
        # è®°å½•æ‰€æœ‰è½®æ¬¡çš„å¯¹è¯
        all_conversations = []
        failed_early = False
        
        try:
            # é€è½®æ‰§è¡Œ
            for i, turn_data in enumerate(turns, 1):
                turn_num = turn_data.get("turn", i)
                user_input = turn_data["user_input"]
                expected_behavior = turn_data["expected_behavior"]
                data_verification = turn_data.get("data_verification")
                
                print(f"\n{'â”€'*80}")
                print(f"ğŸ”„ ç¬¬{turn_num}è½®")
                print(f"{'â”€'*80}")
                print(f"ğŸ“ ç”¨æˆ·ï¼š{user_input}")
                
                # è°ƒç”¨AIå¼•æ“
                response = await ai_engine.process_message(
                    content=user_input,
                    user_id=self.test_user_id,
                    context=test_context
                )
                
                print(f"ğŸ¤– FAAï¼š{response}")
                
                # è®°å½•å¯¹è¯
                all_conversations.append({
                    "turn": turn_num,
                    "user": user_input,
                    "ai": response
                })
                
                # æ•°æ®å±‚éªŒè¯
                data_result = {"score": 40, "details": {}, "issues": []}
                if data_verification:
                    data_validation_result = await self.data_validator.verify(
                        expected=data_verification,
                        test_context=test_context
                    )
                    data_result = data_validation_result.to_dict()
                    
                    # âœ… æ‰“å°æ¯è½®çš„æ•°æ®éªŒè¯ç»“æœ
                    print(f"ğŸ“Š æ•°æ®éªŒè¯ï¼š{data_result['score']:.1f}/40", end="")
                    if data_result['score'] >= 36:
                        print(" âœ…")
                    elif data_result['score'] >= 30:
                        print(" âš ï¸")
                    else:
                        print(" âŒ")
                    
                    # âœ… fail_fastï¼šå¦‚æœæŸè½®ä¸¥é‡å¤±è´¥ï¼Œæå‰ç»ˆæ­¢
                    if fail_fast and data_result['score'] < 20:  # <50%
                        print(f"âš ï¸  ç¬¬{turn_num}è½®ä¸¥é‡å¤±è´¥ï¼Œæå‰ç»ˆæ­¢æµ‹è¯•")
                        failed_early = True
                        turn_results.append({
                            "turn": turn_num,
                            "data_score": data_result["score"],
                            "user_input": user_input,
                            "ai_response": response,
                            "early_termination": True
                        })
                        break
                
                turn_results.append({
                    "turn": turn_num,
                    "data_score": data_result["score"],
                    "user_input": user_input,
                    "ai_response": response
                })
            
            # è®¡ç®—æ€»è€—æ—¶
            duration = (datetime.now() - start_time).total_seconds()
            
            # ===== æ±‡æ€»è¯„åˆ† =====
            # æ•°æ®å±‚ï¼šå–æ‰€æœ‰è½®çš„å¹³å‡åˆ†
            avg_data_score = sum(r["data_score"] for r in turn_results) / len(turn_results)
            
            # å¦‚æœæå‰ç»ˆæ­¢ï¼Œåœ¨issuesä¸­è®°å½•
            if failed_early:
                print(f"\nâš ï¸  æµ‹è¯•æå‰ç»ˆæ­¢äºç¬¬{len(turn_results)}è½®")
                avg_data_score = avg_data_score * 0.7  # æå‰ç»ˆæ­¢æ‰£30%åˆ†æ•°
            
            # åªå¯¹æœ€åä¸€è½®åšå®Œæ•´çš„ä¸‰å±‚è¯„ä¼°ï¼ˆèŠ‚çœæˆæœ¬ï¼‰
            last_turn = turn_results[-1]
            last_turn_data = turns[-1]
            
            print(f"\n{'='*80}")
            print(f"ğŸ’ å¯¹æœ€åä¸€è½®è¿›è¡Œå®Œæ•´è¯„ä¼°...")
            
            # æ„å»ºæœ€åä¸€è½®çš„æµ‹è¯•ç”¨ä¾‹
            final_test_case = {
                "test_id": test_id,
                "test_name": test_name,
                "user_input": last_turn["user_input"],
                "expected_behavior": last_turn_data["expected_behavior"],
                "multi_turn_context": all_conversations[:-1]  # å‰é¢çš„å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
            }
            
            # æ•°æ®å±‚å·²æœ‰åˆ†æ•°
            final_data_result = {"score": avg_data_score, "details": {}, "issues": []}
            
            # å†³å®šæ˜¯å¦è·³è¿‡AIè¯„ä¼°
            data_score_threshold = 36.0  # 90% * 40åˆ†
            skip_ai_evaluation = avg_data_score < data_score_threshold
            
            if skip_ai_evaluation:
                print(f"âš ï¸  æ•°æ®å±‚å¹³å‡å¾—åˆ†è¿‡ä½({avg_data_score:.1f}/40 < {data_score_threshold})")
                print("   è·³è¿‡æ™ºèƒ½å±‚å’Œä½“éªŒå±‚è¯„ä¼°ï¼ˆèŠ‚çœæˆæœ¬ï¼‰")
                
                intelligence_result = {
                    "score": 0,
                    "dimensions": {"intent_understanding": 0, "information_extraction": 0, "context_usage": 0, "response_relevance": 0},
                    "reasoning": "æ•°æ®å±‚æœªè¾¾æ ‡(<90%)ï¼Œè·³è¿‡AIè¯„ä¼°",
                    "suggestions": ["ä¼˜å…ˆä¿®å¤æ•°æ®å±‚é—®é¢˜"]
                }
                
                experience_result = {
                    "score": 0,
                    "dimensions": {"persona_alignment": 0, "language_quality": 0, "information_completeness": 0, "user_friendliness": 0},
                    "reasoning": "æ•°æ®å±‚æœªè¾¾æ ‡(<90%)ï¼Œè·³è¿‡AIè¯„ä¼°",
                    "suggestions": []
                }
            else:
                # æ™ºèƒ½å±‚å’Œä½“éªŒå±‚è¯„ä¼°ï¼ˆä½¿ç”¨æœ€åä¸€è½®çš„AIå›å¤ï¼‰
                db_data = await self._get_latest_memory_data()
                
                print("ğŸ§  æ™ºèƒ½å±‚è¯„ä¼°ä¸­...")
                intelligence_evaluation = await self.ai_evaluator.evaluate_intelligence(
                    test_case=final_test_case,
                    ai_response=last_turn["ai_response"],
                    db_data=db_data
                )
                intelligence_result = intelligence_evaluation.to_dict()
                print(f"   åˆ†æ•°: {intelligence_result['score']:.1f}/40")
                
                print("âœ¨ ä½“éªŒå±‚è¯„ä¼°ä¸­...")
                experience_evaluation = await self.ai_evaluator.evaluate_experience(
                    test_case=final_test_case,
                    ai_response=last_turn["ai_response"]
                )
                experience_result = experience_evaluation.to_dict()
                print(f"   åˆ†æ•°: {experience_result['score']:.1f}/20")
            
            # ç”Ÿæˆå®Œæ•´å¯¹è¯è®°å½•ï¼ˆç”¨äºæŠ¥å‘Šï¼‰
            conversation = []
            for c in all_conversations:
                conversation.append(f"user({self.test_user_id})- {c['user']}")
                conversation.append(f"faa- {c['ai']}")
            
            # è®¡ç®—æ€»åˆ†
            test_score = ScoringSystem.calculate_test_score(
                test_id=test_id,
                test_name=test_name,
                data_result=final_data_result,
                intelligence_result=intelligence_result,
                experience_result=experience_result,
                duration=duration,
                conversation=conversation
            )
            
            # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            self.test_scores.append(test_score)
            
            # æ‰“å°ç»“æœ
            print()
            print(f"{'='*80}")
            if test_score.success:
                print(f"âœ… å¤šè½®æµ‹è¯•é€šè¿‡ - æ€»åˆ†: {test_score.total_score:.1f}/100 (ç­‰çº§{test_score.get_grade()})")
            else:
                print(f"âŒ å¤šè½®æµ‹è¯•å¤±è´¥ - æ€»åˆ†: {test_score.total_score:.1f}/100 (ç­‰çº§{test_score.get_grade()})")
            
            print(f"   æ•°æ®å±‚: {test_score.data_score:.1f}/40 (å¹³å‡)")
            print(f"   æ™ºèƒ½å±‚: {test_score.intelligence_score:.1f}/40")
            print(f"   ä½“éªŒå±‚: {test_score.experience_score:.1f}/20")
            print(f"   å®Œæˆè½®æ•°: {len(turn_results)}/{len(turns)}")
            print(f"   æ€»è€—æ—¶: {duration:.1f}ç§’")
            if failed_early:
                print(f"   âš ï¸  æå‰ç»ˆæ­¢")
            
            if test_score.issues:
                print()
                print("âš ï¸  æ”¹è¿›å»ºè®®:")
                for i, issue in enumerate(test_score.issues[:5], 1):
                    print(f"   {i}. {issue}")
            
            print(f"{'='*80}")
            
            return test_score
            
        except Exception as e:
            logger.error("multi_turn_test_failed", test_id=test_id, error=str(e))
            print(f"âŒ å¤šè½®æµ‹è¯•å¼‚å¸¸ï¼š{e}")
            
            duration = (datetime.now() - start_time).total_seconds()
            
            # ç”Ÿæˆå¯¹è¯è®°å½•
            conversation = []
            if all_conversations:
                for c in all_conversations:
                    conversation.append(f"user({self.test_user_id})- {c['user']}")
                    conversation.append(f"faa- {c['ai']}")
            
            test_score = TestScore(
                test_id=test_id,
                test_name=test_name,
                data_score=0,
                intelligence_score=0,
                experience_score=0,
                total_score=0,
                data_details={},
                intelligence_details={},
                experience_details={},
                duration=duration,
                success=False,
                issues=[f"å¤šè½®æµ‹è¯•å¼‚å¸¸: {str(e)}"],
                conversation=conversation
            )
            
            self.test_scores.append(test_score)
            return test_score
    
    def print_summary(self) -> Dict:
        """
        æ‰“å°æµ‹è¯•æ€»ç»“
        
        Returns:
            æ€»ç»“æ•°æ®å­—å…¸
        """
        print()
        print("=" * 80)
        print(f"ğŸ“Š æµ‹è¯•æ€»ç»“ - {self.test_suite_name}")
        print("=" * 80)
        
        if not self.test_scores:
            print("æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return {}
        
        # è®¡ç®—æ€»ç»“
        summary = ScoringSystem.calculate_suite_summary(self.test_scores)
        
        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        print(f"\næ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»æµ‹è¯•æ•°: {summary.total_cases}")
        print(f"  âœ… é€šè¿‡: {summary.passed} ({summary.pass_rate*100:.1f}%)")
        print(f"  âŒ å¤±è´¥: {summary.failed}")
        print(f"  â±ï¸  æ€»è€—æ—¶: {summary.total_duration:.1f}ç§’")
        print(f"  ğŸ“ˆ å¹³å‡è€—æ—¶: {summary.avg_duration:.1f}ç§’")
        
        # æ‰“å°å¹³å‡åˆ†æ•°
        print(f"\nå¹³å‡åˆ†æ•°:")
        print(f"  æ€»åˆ†: {summary.avg_total_score:.1f}/100")
        print(f"  æ•°æ®å±‚: {summary.avg_data_score:.1f}/40")
        print(f"  æ™ºèƒ½å±‚: {summary.avg_intelligence_score:.1f}/40")
        print(f"  ä½“éªŒå±‚: {summary.avg_experience_score:.1f}/20")
        
        # æ‰“å°ç»´åº¦è¯¦æƒ…
        if summary.dimension_averages:
            print(f"\nç»´åº¦è¯¦æƒ…:")
            for dim, score in sorted(summary.dimension_averages.items(), 
                                    key=lambda x: x[1], reverse=True):
                max_score = 10 if "intent" in dim or "information" in dim or "context" in dim or "response" in dim else 5
                print(f"  {dim}: {score:.1f}/{max_score}")
        
        # æ‰“å°å¤±è´¥ç”¨ä¾‹
        if summary.failed_cases:
            print(f"\nå¤±è´¥ç”¨ä¾‹ ({len(summary.failed_cases)}):")
            for i, case in enumerate(summary.failed_cases, 1):
                print(f"  {i}. [{case['test_id']}] {case['test_name']} - {case['score']:.1f}åˆ†")
                if case['issues']:
                    print(f"     é—®é¢˜: {case['issues'][0]}")
        
        # æ‰“å°è¯¦ç»†ç»“æœ
        print(f"\nè¯¦ç»†ç»“æœ:")
        for i, score in enumerate(self.test_scores, 1):
            status = "âœ…" if score.success else "âŒ"
            grade = score.get_grade()
            print(f"  {i}. {status} [{score.test_id}] {score.test_name}")
            print(f"     åˆ†æ•°: {score.total_score:.1f}/100 (ç­‰çº§{grade})")
            print(f"     æ•°æ®{score.data_score:.0f} + æ™ºèƒ½{score.intelligence_score:.0f} + ä½“éªŒ{score.experience_score:.0f} | è€—æ—¶{score.duration:.1f}s")
        
        print("=" * 80)
        print()
        
        return summary.to_dict()
    
    async def get_latest_memory(self, memory_type: Optional[str] = None) -> Optional[Memory]:
        """
        è·å–æœ€æ–°çš„è®°å¿†è®°å½•ï¼ˆå…¼å®¹æ—§æµ‹è¯•ï¼‰
        """
        try:
            async with get_session() as session:
                # ä½¿ç”¨UUIDå¯¹è±¡è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢
                query = select(Memory).where(
                    Memory.user_id == self.test_user_uuid
                ).order_by(Memory.created_at.desc())
                
                if memory_type:
                    query = query.where(
                        Memory.ai_understanding['type'].astext == memory_type
                    )
                
                result = await session.execute(query)
                return result.scalars().first()
                
        except Exception as e:
            logger.error("get_latest_memory_failed", error=str(e))
            return None

