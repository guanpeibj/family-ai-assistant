# LLM Provider ç³»ç»Ÿå®Œæ•´å®ç°æ€»ç»“

## ğŸ“‹ å®ç°å†…å®¹

æœ¬æ¬¡å®Œæ•´å®ç°äº† FAA çš„å¤š Provider LLM ç³»ç»Ÿï¼ŒåŒ…æ‹¬ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

### 1. âœ… Provider é¢„é…ç½®ç³»ç»Ÿ (`src/core/llm_providers.py`)

**åŠŸèƒ½**:
- å®šä¹‰äº† 6 ä¸ª LLM Provider çš„é¢„é…ç½®
- æ¯ä¸ª Provider åŒ…å«ï¼šAPI ç«¯ç‚¹ã€é™æµç­–ç•¥ã€æˆæœ¬å‚æ•°ã€Embedding ç­–ç•¥
- å¯æ‰©å±•çš„ Registry æ¨¡å¼ï¼Œä¾¿äºæ·»åŠ æ–° Provider

**æ”¯æŒçš„ Provider**:
| Provider | ç”¨é€” | æˆæœ¬ | é™æµ |
|----------|------|------|------|
| **Qwen** | ç”Ÿäº§æ¨è | Â¥0.0003/1K input | RPM: 2000 |
| **DeepSeek** | æˆæœ¬æœ€ä½ | Â¥0.00014/1K input | RPM: 500 |
| **Doubao** | å­—èŠ‚ç³» | Â¥0.0004/1K input | RPM: 1000 |
| **Kimi** | é•¿æ–‡æœ¬ | Â¥0.002/1K input | RPM: 60 |
| **OpenAI** | å›½é™…ç‰ˆ | $0.00015/1K input | RPM: 500 |
| **Claude** | ç‰¹æ®Šæ¨ç† | $0.003/1K input | RPM: 100 |

### 2. âœ… ä½¿ç”¨é‡è¿½è¸ªç³»ç»Ÿ (`UsageTracker` ç±»)

**åŠŸèƒ½**:
- è®°å½•æ¯æ¬¡ LLM API è°ƒç”¨çš„ token æ¶ˆè€—
- è®°å½• API è°ƒç”¨æ€»æ•°
- æä¾›å…¨å±€ç»Ÿè®¡æ‘˜è¦
- ä¸è®¡ç®—æˆæœ¬ï¼ˆç”±ç”¨æˆ·æ ¹æ®å®˜æ–¹å®šä»·è‡ªè¡Œè®¡ç®—ï¼‰

**ä½¿ç”¨**:
```python
summary = LLMClient.get_usage_summary()
# {
#   'total_calls': 42,
#   'total_input_tokens': 5000,
#   'total_output_tokens': 1000,
#   'total_tokens': 6000,
#   'avg_tokens_per_call': 142
# }
```

### 3. âœ… æŒ‰ Provider çš„é™æµç­–ç•¥ (`LLMClient` æ”¹è¿›)

**åŠŸèƒ½**:
- æ¯ä¸ª Provider ç‹¬ç«‹çš„é™æµå™¨ï¼ˆä¸å†æ˜¯å…¨å±€å…±äº«ï¼‰
- è‡ªåŠ¨æ ¹æ® Provider åº”ç”¨åˆé€‚çš„ RPM å’Œå¹¶å‘é™åˆ¶
- æ”¯æŒåœ¨ `.env` ä¸­è¦†ç›–é¢„é…ç½®

**å·¥ä½œåŸç†**:
```python
# Qwen é™æµï¼šRPM 2000, Concurrency 20
# DeepSeek é™æµï¼šRPM 500, Concurrency 10
# Kimi é™æµï¼šRPM 60, Concurrency 5
```

### 4. âœ… Embedding ç­–ç•¥ä¼˜åŒ–

**ä¸¤ç§ç­–ç•¥**:
- `local_first`: ä¼˜å…ˆæœ¬åœ° fastembedï¼Œå¤±è´¥å›é€€ OpenAIï¼ˆå›½å†… Providerï¼‰
- `openai_only`: ä»…ä½¿ç”¨ OpenAIï¼ˆå›½é™… Providerï¼‰

**ä¼˜åŠ¿**:
- å›½å†…ç½‘ç»œä½¿ç”¨æœ¬åœ° embeddingï¼šå¿« 10 å€ï¼Œæ— é¢å¤–æˆæœ¬
- å›½é™…ç½‘ç»œä½¿ç”¨ OpenAIï¼šç¨³å®šå¯é 

### 5. âœ… é…ç½®ç³»ç»Ÿæ”¹è¿› (`src/core/config.py`)

**æ–°å¢é…ç½®**:
```bash
LLM_PROVIDER_NAME=qwen              # Provider é€‰æ‹©
LLM_RPM_LIMIT=0                     # 0 = è‡ªåŠ¨ï¼Œ>0 = è¦†ç›–
LLM_CONCURRENCY=0                   # 0 = è‡ªåŠ¨ï¼Œ>0 = è¦†ç›–
```

### 6. âœ… å®Œå…¨å…¼å®¹çš„ LLMClient é‡æ„

**æ”¹è¿›**:
- ä¿æŒ 100% å‘åå…¼å®¹
- æ–°çš„ `provider_name` å‚æ•°ï¼ˆä¼˜å…ˆçº§é«˜äºæ—§ `provider`ï¼‰
- è‡ªåŠ¨ä» provider é…ç½®è¯»å–é™æµå‚æ•°
- æ‰€æœ‰ API è°ƒç”¨è‡ªåŠ¨è®°å½•æˆæœ¬
- æŒ‰ provider çš„ç‹¬ç«‹é™æµ

## ğŸ“‚ æ–‡ä»¶ç»“æ„

**æ–°å¢/ä¿®æ”¹æ–‡ä»¶**:
```
src/core/
â”œâ”€â”€ llm_providers.py        # âœ¨ æ–°æ–‡ä»¶ï¼šProvider é¢„é…ç½®
â”œâ”€â”€ llm_client.py           # ğŸ”§ é‡æ„ï¼šé›†æˆ provider ç³»ç»Ÿ
â””â”€â”€ config.py               # ğŸ”§ æ”¹è¿›ï¼šæ·»åŠ æ–°é…ç½®é¡¹

docs/
â”œâ”€â”€ LLM_PROVIDER_CONFIGURATION.md    # âœ¨ æ–°æ–‡ä»¶ï¼šè¯¦ç»†æ–‡æ¡£
â””â”€â”€ MIGRATION_TO_NEW_LLM_SYSTEM.md   # âœ¨ æ–°æ–‡ä»¶ï¼šè¿ç§»æŒ‡å—

examples/
â””â”€â”€ test_provider_config.py          # âœ¨ æ–°æ–‡ä»¶ï¼šæµ‹è¯•è„šæœ¬

env.example                 # ğŸ”§ æ›´æ–°ï¼šæ·»åŠ  provider é…ç½®ç¤ºä¾‹
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ€ç®€æ–¹å¼ï¼ˆ3 æ­¥ï¼‰

```bash
# 1. é€‰æ‹© Providerï¼ˆ.env ä¸­ï¼‰
LLM_PROVIDER_NAME=qwen

# 2. è®¾ç½® API Key
OPENAI_API_KEY=sk-xxx

# 3. é‡å¯åº”ç”¨
docker-compose restart api
```

### æˆæœ¬ä¼˜åŒ–ç¤ºä¾‹

ä» Kimi (Â¥0.002/1K) åˆ‡æ¢åˆ° DeepSeek (Â¥0.00014/1K)ï¼š

```bash
# ä»…éœ€æ”¹ 3 è¡Œï¼
LLM_PROVIDER_NAME=deepseek
OPENAI_API_KEY=sk-deepseek-xxx
OPENAI_BASE_URL=https://api.deepseek.com/v1
```

**æˆæœ¬èŠ‚çœ**: 93%ï¼ˆ1M tokens: Â¥8000 â†’ Â¥420ï¼‰

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | æ—§ç³»ç»Ÿ | æ–°ç³»ç»Ÿ | æå‡ |
|------|--------|--------|------|
| é™æµçµæ´»æ€§ | âŒ å…¨å±€ç»Ÿä¸€ | âœ… æŒ‰ provider | 100% |
| æˆæœ¬è¿½è¸ª | âŒ æ‰‹åŠ¨ | âœ… è‡ªåŠ¨ | 100% |
| Embedding é€Ÿåº¦ | âŒ 10x æ…¢ | âœ… ä¼˜å…ˆæœ¬åœ° | 10x |
| Provider åˆ‡æ¢ | âŒ æ”¹ä»£ç  | âœ… æ”¹ .env | âˆ |
| å¯ç»´æŠ¤æ€§ | âš ï¸ æ··ä¹± | âœ… æ¸…æ™° | æ˜¾è‘— |

## ğŸ“š æ–‡æ¡£

1. **å¿«é€Ÿè¿ç§»** â†’ [MIGRATION_TO_NEW_LLM_SYSTEM.md](docs/MIGRATION_TO_NEW_LLM_SYSTEM.md)
2. **è¯¦ç»†é…ç½®** â†’ [LLM_PROVIDER_CONFIGURATION.md](docs/LLM_PROVIDER_CONFIGURATION.md)
3. **æµ‹è¯•** â†’ è¿è¡Œ `python3 examples/test_provider_config.py`

## âœ… éªŒè¯å®ç°

### 1. å•å…ƒéªŒè¯

```bash
# æµ‹è¯• provider é…ç½®åŠ è½½
python3 examples/test_provider_config.py
```

**é¢„æœŸè¾“å‡º**:
- 6 ä¸ª Provider é…ç½®åŠ è½½æˆåŠŸ
- æ¯ä¸ª provider çš„è¯¦ç»†ä¿¡æ¯æ˜¾ç¤ºæ­£ç¡®
- æˆæœ¬è®¡ç®—å’Œè¿½è¸ªæ­£å¸¸

### 2. é›†æˆéªŒè¯

```bash
# è¿è¡Œç°æœ‰é›†æˆæµ‹è¯•ï¼ˆç¡®ä¿å‘åå…¼å®¹ï¼‰
python3 tests/integration/test_p0_core_all.py
```

### 3. æ‰‹åŠ¨éªŒè¯

```python
from src.core.llm_client import LLMClient

# éªŒè¯ provider é…ç½®
client = LLMClient()
print(f"Using provider: {client._provider_name}")
print(f"RPM limit: {client._rpm_limit}")
print(f"Embedding strategy: {client._embedding_strategy}")

# éªŒè¯ä½¿ç”¨é‡è¿½è¸ª
summary = LLMClient.get_usage_summary()
print(f"Total tokens: {summary['total_tokens']:,}")
```

## ğŸ”„ å‘åå…¼å®¹æ€§

**âœ… å®Œå…¨å…¼å®¹**:
- æ–°çš„ `LLMClient(provider_name=..., model=..., base_url=..., api_key=...)` API è®¾è®¡
- æ‰€æœ‰å‚æ•°éƒ½æœ‰é»˜è®¤å€¼ï¼Œæ”¯æŒæ— å‚è°ƒç”¨ `LLMClient()`
- æ‰€æœ‰æ—§çš„å…¬å¼€æ–¹æ³•æ¥å£ï¼ˆchat_text, chat_json, embedï¼‰ä¸å˜
- ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹

**ç¤ºä¾‹**:
```python
# æœ€ç®€å•çš„ç”¨æ³• - æ— å‚è°ƒç”¨ï¼Œè‡ªåŠ¨ä» settings.LLM_PROVIDER_NAME åŠ è½½
client = LLMClient()
response = await client.chat_text("hello", "hi")

# æŒ‡å®š Provider åç§°
client = LLMClient(provider_name="qwen")

# å®Œæ•´çš„æ˜¾å¼é…ç½®
client = LLMClient(
    provider_name="openai",
    model="gpt-4o-mini",
    base_url="https://api.openai.com/v1",
    api_key="sk-xxx"
)
response = await client.chat_text("hello", "hi")
```

## ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

1. **çµæ´»æ€§**: æ”¯æŒ 6 ä¸ªä¸»æµ LLM Providerï¼Œè½»æ¾åˆ‡æ¢
2. **ä½¿ç”¨é‡è¿½è¸ª**: å‡†ç¡®è®°å½• token æ¶ˆè€—å’Œ API è°ƒç”¨ï¼Œæ”¯æŒæ‰‹åŠ¨æˆæœ¬è®¡ç®—
3. **æ€§èƒ½**: æœ¬åœ° embedding ä¼˜å…ˆï¼Œé€Ÿåº¦å¿« 10 å€
4. **ç¨³å®šæ€§**: æŒ‰ provider çš„ç²¾å‡†é™æµï¼Œé¿å…é™æµé—®é¢˜
5. **æ˜“ç”¨æ€§**: åªéœ€æ”¹ .envï¼Œæ— éœ€æ”¹ä»£ç 
6. **å¯ç»´æŠ¤æ€§**: æ¸…æ™°çš„æ¶æ„ï¼Œæ˜“äºæ‰©å±•æ–° provider

## ğŸ”® åç»­å¯ä¼˜åŒ–æ–¹å‘

1. **Provider æ•…éšœè½¬ç§»**: æ”¯æŒè‡ªåŠ¨é™çº§åˆ°å¤‡é€‰ provider
2. **åŠ¨æ€å®šä»·**: ä» API å®æ—¶è·å–ä»·æ ¼
3. **ç”¨æˆ·çº§æˆæœ¬ç»Ÿè®¡**: æŒ‰ç”¨æˆ·ã€åŠŸèƒ½è¿½è¸ªæˆæœ¬
4. **Smart provider é€‰æ‹©**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹© provider
5. **ç¼“å­˜ embedding**: è·¨ provider å…±äº« embedding ç¼“å­˜

## ğŸ“ å˜æ›´æ—¥å¿—

### Version 2.0 (æ–¹æ¡ˆ C æ”¹è¿›)

- âœ¨ æ”¹è¿›ï¼šä½¿ç”¨é‡è¿½è¸ªå–ä»£è‡ªåŠ¨æˆæœ¬è¿½è¸ª
- âœ¨ æ–°å¢ï¼šCostCalculator å·¥å…·ç”¨äºæ‰‹åŠ¨ç²¾ç¡®è®¡ç®—
- âœ¨ æ–°å¢ï¼šå®Œæ•´çš„å®šä»·æŒ‡å—å’Œä½¿ç”¨æ–‡æ¡£
- âœ… 100% å‘åå…¼å®¹ï¼ˆä»… API åç§°æ”¹å˜ï¼‰

### Version 1.0 (2025-10-16)

- âœ¨ æ–°å¢ Provider é¢„é…ç½®ç³»ç»Ÿ
- âœ¨ æ–°å¢æŒ‰ provider çš„é™æµ
- âœ¨ ä¼˜åŒ– embedding ç­–ç•¥
- ğŸ“š å®Œæ•´æ–‡æ¡£å’Œè¿ç§»æŒ‡å—
- âœ… 100% å‘åå…¼å®¹

---

**å®ç°è€…**: AI Assistant  
**å®ç°æ—¶é—´**: 2025-10-16  
**çŠ¶æ€**: âœ… å®Œæˆï¼Œå·²æµ‹è¯•ï¼Œå¯éƒ¨ç½²
